{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:48.363412Z",
     "iopub.status.busy": "2025-01-23T17:10:48.361768Z",
     "iopub.status.idle": "2025-01-23T17:10:51.311096Z",
     "shell.execute_reply": "2025-01-23T17:10:51.309942Z",
     "shell.execute_reply.started": "2025-01-23T17:10:48.363351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.io as io\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.314696Z",
     "iopub.status.busy": "2025-01-23T17:10:51.313218Z",
     "iopub.status.idle": "2025-01-23T17:10:51.336604Z",
     "shell.execute_reply": "2025-01-23T17:10:51.335354Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.314637Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/bhw1\n"
     ]
    }
   ],
   "source": [
    "%cd bhw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.339331Z",
     "iopub.status.busy": "2025-01-23T17:10:51.337907Z",
     "iopub.status.idle": "2025-01-23T17:10:51.442606Z",
     "shell.execute_reply": "2025-01-23T17:10:51.441458Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.339260Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trainval_00000.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trainval_00001.jpg</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trainval_00002.jpg</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trainval_00003.jpg</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trainval_00004.jpg</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>trainval_99995.jpg</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>trainval_99996.jpg</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>trainval_99997.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>trainval_99998.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>trainval_99999.jpg</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id  Category\n",
       "0      trainval_00000.jpg         7\n",
       "1      trainval_00001.jpg       198\n",
       "2      trainval_00002.jpg       161\n",
       "3      trainval_00003.jpg       131\n",
       "4      trainval_00004.jpg       107\n",
       "...                   ...       ...\n",
       "99995  trainval_99995.jpg        72\n",
       "99996  trainval_99996.jpg       194\n",
       "99997  trainval_99997.jpg         6\n",
       "99998  trainval_99998.jpg        29\n",
       "99999  trainval_99999.jpg       167\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('labels.csv')\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.446535Z",
     "iopub.status.busy": "2025-01-23T17:10:51.445207Z",
     "iopub.status.idle": "2025-01-23T17:10:51.472169Z",
     "shell.execute_reply": "2025-01-23T17:10:51.470957Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.446491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(labels_df, test_size=0.05, random_state=42)\n",
    "img_dir = 'trainval' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.474908Z",
     "iopub.status.busy": "2025-01-23T17:10:51.473515Z",
     "iopub.status.idle": "2025-01-23T17:10:51.492597Z",
     "shell.execute_reply": "2025-01-23T17:10:51.491413Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.474852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_df, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = io.read_image(img_path)  \n",
    "        label = self.labels_df.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.494508Z",
     "iopub.status.busy": "2025-01-23T17:10:51.493780Z",
     "iopub.status.idle": "2025-01-23T17:10:51.510294Z",
     "shell.execute_reply": "2025-01-23T17:10:51.509098Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.494453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ConvertImageDtype(torch.float),\n",
    "    v2.RandomHorizontalFlip(p=0.5),  \n",
    "    v2.RandomApply([v2.RandomCrop(40, padding=4)], p=0.5),\n",
    "    v2.RandomApply([v2.RandomRotation(degrees=15)], p=0.5),\n",
    "    v2.RandomApply([v2.Grayscale()], p=0.5),\n",
    "    v2.RandomApply([v2.GaussianBlur(kernel_size=3)], p=0.5),\n",
    "    v2.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    v2.Normalize((0.5692, 0.5448, 0.4934), (0.1823, 0.1810, 0.1854)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:51.512725Z",
     "iopub.status.busy": "2025-01-23T17:10:51.511448Z",
     "iopub.status.idle": "2025-01-23T17:10:51.527319Z",
     "shell.execute_reply": "2025-01-23T17:10:51.526155Z",
     "shell.execute_reply.started": "2025-01-23T17:10:51.512660Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(img_dir=img_dir, labels_df=train_df, transform=transform)\n",
    "val_dataset = MyDataset(img_dir=img_dir, labels_df=val_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:53.125272Z",
     "iopub.status.busy": "2025-01-23T17:10:53.123888Z",
     "iopub.status.idle": "2025-01-23T17:10:53.160597Z",
     "shell.execute_reply": "2025-01-23T17:10:53.159337Z",
     "shell.execute_reply.started": "2025-01-23T17:10:53.125230Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "       \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "       \n",
    "        # self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64, stride=1)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "        self.fc = nn.Linear(512 * ResBlock.expansion, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        # x = self.max_pool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:54.314308Z",
     "iopub.status.busy": "2025-01-23T17:10:54.313065Z",
     "iopub.status.idle": "2025-01-23T17:10:54.330825Z",
     "shell.execute_reply": "2025-01-23T17:10:54.329719Z",
     "shell.execute_reply.started": "2025-01-23T17:10:54.314265Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T17:10:55.022306Z",
     "iopub.status.busy": "2025-01-23T17:10:55.021003Z",
     "iopub.status.idle": "2025-01-23T17:10:55.037203Z",
     "shell.execute_reply": "2025-01-23T17:10:55.036121Z",
     "shell.execute_reply.started": "2025-01-23T17:10:55.022263Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T07:18:49.844991Z",
     "iopub.status.busy": "2025-01-23T07:18:49.844057Z",
     "iopub.status.idle": "2025-01-23T07:18:50.314300Z",
     "shell.execute_reply": "2025-01-23T07:18:50.313401Z",
     "shell.execute_reply.started": "2025-01-23T07:18:49.844952Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=200).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "#scheduler = CyclicLR(optimizer, base_lr=1e-4, max_lr=0.1, step_size_up=400, mode='triangular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-23T07:25:31.276867Z",
     "iopub.status.busy": "2025-01-23T07:25:31.275666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80]\n",
      "Train Loss: 5.2912 | Train Acc: 0.71%\n",
      "Val Loss: 5.2502 | Val Acc: 1.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [06:20<8:20:52, 380.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [2/80]\n",
      "Train Loss: 5.2375 | Train Acc: 1.05%\n",
      "Val Loss: 5.1926 | Val Acc: 1.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [12:38<8:12:59, 379.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [3/80]\n",
      "Train Loss: 5.1775 | Train Acc: 1.52%\n",
      "Val Loss: 5.1237 | Val Acc: 1.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [18:58<8:07:13, 379.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [4/80]\n",
      "Train Loss: 5.1032 | Train Acc: 2.12%\n",
      "Val Loss: 6.3105 | Val Acc: 2.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [25:18<8:00:54, 379.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [5/80]\n",
      "Train Loss: 5.0828 | Train Acc: 2.33%\n",
      "Val Loss: 5.0219 | Val Acc: 2.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [31:39<7:54:58, 379.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [6/80]\n",
      "Train Loss: 5.0037 | Train Acc: 3.05%\n",
      "Val Loss: 4.9402 | Val Acc: 3.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [38:00<7:49:03, 380.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [7/80]\n",
      "Train Loss: 4.9265 | Train Acc: 3.85%\n",
      "Val Loss: 4.8260 | Val Acc: 5.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [44:20<7:42:39, 380.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [8/80]\n",
      "Train Loss: 4.8411 | Train Acc: 5.00%\n",
      "Val Loss: 4.7826 | Val Acc: 5.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [50:39<7:35:53, 379.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [9/80]\n",
      "Train Loss: 4.7569 | Train Acc: 6.03%\n",
      "Val Loss: 4.7080 | Val Acc: 6.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [56:59<7:29:28, 379.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [10/80]\n",
      "Train Loss: 4.6693 | Train Acc: 7.17%\n",
      "Val Loss: 4.6012 | Val Acc: 8.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [1:03:18<7:22:54, 379.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [11/80]\n",
      "Train Loss: 4.5664 | Train Acc: 8.64%\n",
      "Val Loss: 4.5407 | Val Acc: 9.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [1:09:38<7:16:46, 379.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [12/80]\n",
      "Train Loss: 4.4575 | Train Acc: 10.27%\n",
      "Val Loss: 4.3883 | Val Acc: 11.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [1:15:56<7:09:53, 379.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [13/80]\n",
      "Train Loss: 4.3861 | Train Acc: 11.28%\n",
      "Val Loss: 4.3024 | Val Acc: 13.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [1:22:16<7:03:43, 379.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [14/80]\n",
      "Train Loss: 4.3093 | Train Acc: 12.72%\n",
      "Val Loss: 4.2551 | Val Acc: 13.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [1:28:35<6:57:11, 379.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [15/80]\n",
      "Train Loss: 4.2461 | Train Acc: 13.83%\n",
      "Val Loss: 4.1993 | Val Acc: 14.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [1:34:55<6:51:02, 379.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [16/80]\n",
      "Train Loss: 4.1982 | Train Acc: 14.57%\n",
      "Val Loss: 4.1657 | Val Acc: 16.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/80 [1:41:15<6:45:08, 379.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [1:47:34<6:38:35, 379.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/80]\n",
      "Train Loss: 4.1395 | Train Acc: 15.74%\n",
      "Val Loss: 4.1053 | Val Acc: 16.42%\n",
      "Epoch [18/80]\n",
      "Train Loss: 4.0888 | Train Acc: 16.75%\n",
      "Val Loss: 4.0088 | Val Acc: 18.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [1:53:54<6:32:19, 379.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [2:00:12<6:25:17, 378.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/80]\n",
      "Train Loss: 4.0441 | Train Acc: 17.65%\n",
      "Val Loss: 4.1447 | Val Acc: 16.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [2:06:29<6:18:28, 378.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/80]\n",
      "Train Loss: 4.0068 | Train Acc: 18.32%\n",
      "Val Loss: 4.1962 | Val Acc: 15.04%\n",
      "Epoch [21/80]\n",
      "Train Loss: 3.9628 | Train Acc: 19.18%\n",
      "Val Loss: 3.9538 | Val Acc: 20.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [2:12:48<6:12:19, 378.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [22/80]\n",
      "Train Loss: 3.9414 | Train Acc: 19.63%\n",
      "Val Loss: 3.9105 | Val Acc: 20.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [2:19:08<6:06:16, 378.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [2:25:25<5:59:28, 378.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/80]\n",
      "Train Loss: 3.8845 | Train Acc: 20.86%\n",
      "Val Loss: 3.9207 | Val Acc: 20.00%\n",
      "Epoch [24/80]\n",
      "Train Loss: 3.8394 | Train Acc: 21.76%\n",
      "Val Loss: 3.8604 | Val Acc: 22.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [2:31:43<5:53:06, 378.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [2:38:00<5:46:28, 377.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/80]\n",
      "Train Loss: 3.8013 | Train Acc: 22.63%\n",
      "Val Loss: 3.8516 | Val Acc: 21.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [2:44:19<5:40:29, 378.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/80]\n",
      "Train Loss: 3.7673 | Train Acc: 23.33%\n",
      "Val Loss: 3.9552 | Val Acc: 21.26%\n",
      "Epoch [27/80]\n",
      "Train Loss: 3.7377 | Train Acc: 24.12%\n",
      "Val Loss: 3.8057 | Val Acc: 22.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [2:50:39<5:34:27, 378.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [28/80]\n",
      "Train Loss: 3.6980 | Train Acc: 24.73%\n",
      "Val Loss: 3.7639 | Val Acc: 24.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [2:56:58<5:28:25, 378.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [29/80]\n",
      "Train Loss: 3.6640 | Train Acc: 25.71%\n",
      "Val Loss: 3.7375 | Val Acc: 24.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [3:03:17<5:22:03, 378.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [30/80]\n",
      "Train Loss: 3.6318 | Train Acc: 26.36%\n",
      "Val Loss: 3.7396 | Val Acc: 24.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [3:09:37<5:16:04, 379.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [3:15:54<5:09:12, 378.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/80]\n",
      "Train Loss: 3.5994 | Train Acc: 27.22%\n",
      "Val Loss: 3.8232 | Val Acc: 23.68%\n",
      "Epoch [32/80]\n",
      "Train Loss: 3.5720 | Train Acc: 27.85%\n",
      "Val Loss: 3.6720 | Val Acc: 26.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [3:22:13<5:02:52, 378.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [3:28:30<4:56:15, 378.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/80]\n",
      "Train Loss: 3.5413 | Train Acc: 28.41%\n",
      "Val Loss: 3.6975 | Val Acc: 25.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [3:34:48<4:49:55, 378.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/80]\n",
      "Train Loss: 3.5128 | Train Acc: 29.02%\n",
      "Val Loss: 3.7268 | Val Acc: 24.88%\n",
      "Epoch [35/80]\n",
      "Train Loss: 3.4882 | Train Acc: 29.88%\n",
      "Val Loss: 3.5781 | Val Acc: 27.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [3:41:07<4:43:42, 378.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n",
      "Epoch [36/80]\n",
      "Train Loss: 3.4676 | Train Acc: 30.24%\n",
      "Val Loss: 3.5925 | Val Acc: 27.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [3:47:24<4:37:17, 378.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [3:53:43<4:31:00, 378.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/80]\n",
      "Train Loss: 3.4359 | Train Acc: 30.92%\n",
      "Val Loss: 3.6778 | Val Acc: 26.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [4:00:00<4:24:31, 377.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/80]\n",
      "Train Loss: 3.4161 | Train Acc: 31.48%\n",
      "Val Loss: 3.5846 | Val Acc: 27.56%\n",
      "Epoch [39/80]\n",
      "Train Loss: 3.3923 | Train Acc: 32.18%\n",
      "Val Loss: 3.5706 | Val Acc: 29.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [4:06:19<4:18:26, 378.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated and saved to ./best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [4:12:37<4:12:04, 378.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/80]\n",
      "Train Loss: 3.3679 | Train Acc: 32.89%\n",
      "Val Loss: 3.5827 | Val Acc: 27.80%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 80\n",
    "best_val_acc = 0.0\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "save_dir = \"./\"\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'train_acc_history': train_acc_history,\n",
    "            'val_acc_history': val_acc_history\n",
    "        }, best_model_path)\n",
    "        print(f'Best model updated and saved to {best_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1, num_epochs + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss_history, label='train_loss', marker='o')\n",
    "plt.plot(epochs, val_loss_history, label='val_loss', marker='o')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc_history, label='train_acc', marker='o')\n",
    "plt.plot(epochs, val_acc_history, label='val_acc', marker='o')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:02:50.465383Z",
     "iopub.status.busy": "2025-01-23T16:02:50.464092Z",
     "iopub.status.idle": "2025-01-23T16:02:50.487568Z",
     "shell.execute_reply": "2025-01-23T16:02:50.486312Z",
     "shell.execute_reply.started": "2025-01-23T16:02:50.465347Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = sorted([f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return img_name, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:02:51.219930Z",
     "iopub.status.busy": "2025-01-23T16:02:51.218690Z",
     "iopub.status.idle": "2025-01-23T16:02:51.335824Z",
     "shell.execute_reply": "2025-01-23T16:02:51.334722Z",
     "shell.execute_reply.started": "2025-01-23T16:02:51.219886Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5692, 0.5448, 0.4934), (0.1823, 0.1810, 0.1854)) \n",
    "])\n",
    "test_img_dir = 'test'\n",
    "test_dataset = TestDataset(img_dir=test_img_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for img_names, images in test_loader:\n",
    "        images = images.cuda()\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        for img_name, pred in zip(img_names, preds):\n",
    "            results.append((img_name, int(pred)))  \n",
    "\n",
    "ans = pd.DataFrame(results, columns=['Id', 'Category'])\n",
    "ans.to_csv('labels_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model_after_80_epochs.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6518942,
     "sourceId": 10535759,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
