{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install torchtext==0.18.0\n",
    "# %pip install torch==2.3.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашка была вдохновлена следующими туториалами:\n",
    "    https://medium.com/@monimoyd/step-by-step-machine-translation-using-transformer-and-multi-head-attention-96435675be75\n",
    "    https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sacrebleu \n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd bhw-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "    \n",
    "de_tokenizer = simple_tokenizer\n",
    "en_tokenizer = simple_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_filepaths = ('train.de-en.de', 'train.de-en.en')\n",
    "val_filepaths = ('val.de-en.de', 'val.de-en.en')\n",
    "test_filepaths = 'test1.de-en.de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens(filepath, tokenizer):\n",
    "    with io.open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            yield tokenizer(line)\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_filepaths[0], de_tokenizer),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=8\n",
    ")\n",
    "de_vocab.set_default_index(de_vocab['<unk>'])\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_filepaths[1], en_tokenizer),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=8\n",
    ")\n",
    "en_vocab.set_default_index(en_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(filepaths):\n",
    "    if (len(filepaths) == 2):\n",
    "        raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "        raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "        data = []\n",
    "        for raw_de, raw_en in zip(raw_de_iter, raw_en_iter):\n",
    "            de_tensor = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
    "                                       dtype=torch.long)\n",
    "            en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
    "                                       dtype=torch.long)\n",
    "            data.append((de_tensor, en_tensor))\n",
    "        return data\n",
    "    else:\n",
    "        raw_de_iter = iter(io.open(filepaths, encoding=\"utf8\"))\n",
    "        data = []\n",
    "        for raw_de in raw_de_iter:\n",
    "            de_tensor = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
    "                                       dtype=torch.long)\n",
    "            data.append(de_tensor)\n",
    "        return data\n",
    "        \n",
    "\n",
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([de_vocab['<bos>']]), de_item, torch.tensor([de_vocab['<eos>']])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([en_vocab['<bos>']]), en_item, torch.tensor([en_vocab['<eos>']])], dim=0))\n",
    "\n",
    "    de_batch = pad_sequence(de_batch, padding_value=de_vocab['<pad>']).transpose(0,1)  \n",
    "    en_batch = pad_sequence(en_batch, padding_value=en_vocab['<pad>']).transpose(0,1)  # (batch_size, seq_len)\n",
    "\n",
    "    return de_batch, en_batch\n",
    "\n",
    "\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, collate_fn=generate_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int,\n",
    "                 emb_dim: int = 512,\n",
    "                 nhead: int = 8,\n",
    "                 num_encoder_layers: int = 6,\n",
    "                 num_decoder_layers: int = 6,\n",
    "                 dim_feedforward: int = 2048,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.src_tok_emb = nn.Embedding(input_dim, emb_dim)\n",
    "        self.tgt_tok_emb = nn.Embedding(output_dim, emb_dim)\n",
    "        self.positional_encoding = PositionalEncoding(emb_dim, dropout)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model=emb_dim,\n",
    "                                          nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)  \n",
    "\n",
    "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt, \n",
    "                src_mask=None, tgt_mask=None, memory_mask=None,\n",
    "                src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        src: (batch_size, src_seq_len)\n",
    "        tgt: (batch_size, tgt_seq_len)\n",
    "        \"\"\"\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src) * math.sqrt(self.emb_dim)) \n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt) * math.sqrt(self.emb_dim))  \n",
    "        outs = self.transformer(src_emb, tgt_emb,\n",
    "                                src_mask=src_mask,\n",
    "                                tgt_mask=tgt_mask,\n",
    "                                memory_mask=memory_mask,\n",
    "                                src_key_padding_mask=src_key_padding_mask,\n",
    "                                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                                memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return self.fc_out(outs)  \n",
    "\n",
    "\n",
    "\n",
    "input_dim = len(de_vocab)  \n",
    "output_dim = len(en_vocab)  \n",
    "\n",
    "emb_dim = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.2\n",
    "\n",
    "model = Seq2SeqTransformer(input_dim, output_dim,\n",
    "                           emb_dim=emb_dim,\n",
    "                           nhead=nhead,\n",
    "                           num_encoder_layers=num_encoder_layers,\n",
    "                           num_decoder_layers=num_decoder_layers,\n",
    "                           dim_feedforward=dim_feedforward,\n",
    "                           dropout=dropout).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence_transformer(model, src_tensor, trg_vocab, max_len=100):\n",
    "    model.eval()\n",
    "    src_tensor = src_tensor.to(device)\n",
    "\n",
    "    if src_tensor.dim() == 1:\n",
    "        src_tensor = src_tensor.unsqueeze(0) \n",
    "\n",
    "    src_mask = None \n",
    "    src_emb = model.positional_encoding(model.src_tok_emb(src_tensor) * math.sqrt(model.emb_dim))\n",
    "\n",
    "   \n",
    "    memory = model.transformer.encoder(\n",
    "        src_emb, src_key_padding_mask=(src_tensor == PAD_IDX)\n",
    "    )  \n",
    "\n",
    "    trg_indexes = [trg_vocab['<bos>']]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device) \n",
    "        tgt_mask = generate_square_subsequent_mask(trg_tensor.shape[1]).to(device)\n",
    "\n",
    "        tgt_emb = model.positional_encoding(model.tgt_tok_emb(trg_tensor) * math.sqrt(model.emb_dim))\n",
    "\n",
    "        out = model.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=(trg_tensor == PAD_IDX),\n",
    "            memory_key_padding_mask=(src_tensor == PAD_IDX)\n",
    "        )\n",
    "\n",
    "        out = out[:, -1, :] \n",
    "        prob = model.fc_out(out)  # (batch_size, vocab_size)\n",
    "\n",
    "        pred_token = prob.argmax(1).item()  \n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    return trg_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_bleu(model, iterator, trg_vocab, max_len=100):\n",
    "    model.eval()\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            for i in range(src.shape[0]):  \n",
    "                src_sentence = src[i, :]\n",
    "                trg_sentence = trg[i, :]\n",
    "\n",
    "                pred_indexes = translate_sentence_transformer(model, src_sentence, trg_vocab, max_len=max_len)\n",
    "\n",
    "                eos_index = trg_vocab['<eos>'] if '<eos>' in trg_vocab else -1\n",
    "\n",
    "                pred_tokens = [trg_vocab.get_itos()[i] for i in pred_indexes if i not in {trg_vocab['<bos>'], eos_index, PAD_IDX}]\n",
    "\n",
    "                hypothesis = \" \".join(pred_tokens)\n",
    "\n",
    "                trg_tokens = [trg_vocab.get_itos()[i] for i in trg_sentence.tolist() if i not in {trg_vocab['<bos>'], eos_index, PAD_IDX}]\n",
    "\n",
    "                reference = \" \".join(trg_tokens).strip()\n",
    "\n",
    "                hypotheses.append(hypothesis)\n",
    "                references.append([reference])  \n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(hypotheses, references)\n",
    "    return bleu.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_masks(src, tgt):\n",
    "    tgt_seq_len = tgt.shape[1] \n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len).to(src.device)\n",
    "    \n",
    "    src_padding_mask = (src == PAD_IDX)  \n",
    "    tgt_padding_mask = (tgt == PAD_IDX) \n",
    "\n",
    "    return None, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float, scheduler):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for _, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src_mask, tgt_mask, src_key_padding_mask, tgt_key_padding_mask = create_masks(src, trg)\n",
    "\n",
    "        output = model(src, trg, src_mask=src_mask, tgt_mask=tgt_mask, \n",
    "                       src_key_padding_mask=src_key_padding_mask, \n",
    "                       tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        output = output[:, :-1, :].reshape(-1, output.shape[-1])  \n",
    "        trg = trg[:, 1:].reshape(-1)  \n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "\n",
    "def epoch_time(start_time: float, end_time: float):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_IDX = en_vocab.get_stoi()['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9, weight_decay=1e-4)\n",
    "warmup_steps = 2000\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return (emb_dim ** -0.5) * min(step ** (-0.5), step * (warmup_steps ** (-1.5)))\n",
    "    \n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "best_valid_bleu = 0  \n",
    "\n",
    "train_losses = []\n",
    "valid_bleus = []\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP, scheduler)\n",
    "    valid_bleu = evaluate_bleu(model, valid_iter, en_vocab)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    train_losses.append(train_loss)\n",
    "    valid_bleus.append(valid_bleu)\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. BLEU: {valid_bleu:.2f}')\n",
    "\n",
    "   \n",
    "torch.save(model.state_dict(), 'best-model-lr.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 14+1), train_losses, marker='o', label=\"Train Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, N_EPOCHS+1), valid_bleus, marker='o', color='green', label=\"Validation BLEU\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BLEU Score\")\n",
    "plt.title(\"Validation BLEU per Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_translate_sentence(model, src_tensor, trg_vocab, beam_width=5, max_len=100, length_penalty=0.75):\n",
    "    model.eval()\n",
    "    st = src_tensor.to(device)\n",
    "    if st.dim() == 1:\n",
    "        st = st.unsqueeze(0)\n",
    "\n",
    "    emb = model.positional_encoding(model.src_tok_emb(st) * math.sqrt(model.emb_dim))\n",
    "    mem = model.transformer.encoder(emb, src_key_padding_mask=(st == PAD_IDX))\n",
    "\n",
    "    init_token = trg_vocab['<bos>']\n",
    "    beams = [([init_token], 0.0)]\n",
    "    fin = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, scr in beams:\n",
    "            if seq[-1] == trg_vocab['<eos>']: #stop if we found the end\n",
    "                norm = scr / (len(seq) ** length_penalty)\n",
    "                fin.append((seq, norm))\n",
    "                continue\n",
    "\n",
    "            ts = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
    "            mask = generate_square_subsequent_mask(ts.shape[1]).to(device)\n",
    "            te = model.positional_encoding(model.tgt_tok_emb(ts) * math.sqrt(model.emb_dim))\n",
    "\n",
    "            out = model.transformer.decoder(\n",
    "                te, mem,\n",
    "                tgt_mask=mask,\n",
    "                tgt_key_padding_mask=(ts == PAD_IDX),\n",
    "                memory_key_padding_mask=(st == PAD_IDX)\n",
    "            )\n",
    "            out = out[:, -1, :]\n",
    "            lg = model.fc_out(out)\n",
    "            lp = torch.log_softmax(lg, dim=-1)\n",
    "            top_lp, top_idx = torch.topk(lp, beam_width, dim=-1)\n",
    "            top_lp = top_lp.squeeze(0)\n",
    "            top_idx = top_idx.squeeze(0)\n",
    "\n",
    "            for token, token_lp in zip(top_idx, top_lp):\n",
    "                new_seq = seq + [token.item()]\n",
    "                new_scr = scr + token_lp.item()\n",
    "                new_beams.append((new_seq, new_scr))\n",
    "\n",
    "        if len(fin) >= beam_width:\n",
    "            break\n",
    "\n",
    "        new_beams = sorted(new_beams, key=lambda x: x[1], reverse=True)\n",
    "        beams = new_beams[:beam_width]\n",
    "\n",
    "    if not fin:\n",
    "        fin = [(s, scr / (len(s) ** length_penalty)) for s, scr in beams] #score normalization\n",
    "\n",
    "    best_seq, _ = sorted(fin, key=lambda x: x[1], reverse=True)[0]\n",
    "    return best_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch_test(data_batch):\n",
    "    de_batch = []\n",
    "    for de_item in data_batch:\n",
    "        de_tensor = torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])])\n",
    "        de_batch.append(de_tensor)\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)  # (seq_len, batch_size)\n",
    "    return de_batch\n",
    "\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "        batch = batch.to(device)  \n",
    "        for i in range(batch.shape[1]): \n",
    "            src_sentence = batch[:, i]  \n",
    "            predicted_indices = beam_search_translate_sentence(model, src_sentence, en_vocab)\n",
    "\n",
    "            tokens = [en_vocab.get_itos()[i] for i in predicted_indices if i not in {BOS_IDX, EOS_IDX, PAD_IDX}]\n",
    "\n",
    "            prediction = \" \".join(tokens)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "\n",
    "with open(\"test.de-en-final-final-model.en\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "    for pred in predictions:\n",
    "        f.write(pred + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6697772,
     "sourceId": 10792765,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6845261,
     "sourceId": 10998557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
